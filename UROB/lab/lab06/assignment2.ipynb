{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.load('data/utek.npy')\n",
    "label = np.load('data/label.npy')\n",
    "\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "ax1.imshow(image)\n",
    "ax1.axis('off')\n",
    "ax1.title.set_text('Image')\n",
    "ax2.imshow(label)\n",
    "ax2.axis('off')\n",
    "ax2.title.set_text('Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2D(torch.nn.Module):\n",
    "    def __init__(self, channels, kernel_size, stride=1, padding=None):\n",
    "        super(Conv2D, self).__init__()\n",
    "\n",
    "        self.conv = ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = ...\n",
    "        x = ...\n",
    "        x = ...\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(y_pred, y_true):\n",
    "    \"\"\" L2 loss\n",
    "    :param y_pred: tensor of shape (height, width)\n",
    "    :param y_true: tensor of shape (height, width)\n",
    "    :return: scalar\n",
    "    \"\"\"\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Convolutional Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Qt5Agg')\n",
    "\n",
    "# parameters\n",
    "learning_rate = ...\n",
    "n_iterations = ...\n",
    "kernel_size = ...\n",
    "padding = ...\n",
    "\n",
    "# creating model\n",
    "model = Conv2D(channels=..., kernel_size=kernel_size, stride=1, padding=padding)\n",
    "optimizer = ...\n",
    "\n",
    "# converting input to tensors\n",
    "x = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float)\n",
    "y = torch.tensor(label, dtype=torch.float)\n",
    "\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "\n",
    "# training loop\n",
    "for i in range(n_iterations):\n",
    "\n",
    "    # Compute positions of the joints\n",
    "    output = model.forward(x)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = l2_loss(output, y)\n",
    "\n",
    "    # Compute gradient\n",
    "    loss.backward()\n",
    "\n",
    "    # Make an optimization step and reset the gradient\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f'Iteration: {i}, loss = {loss.detach().numpy()}')\n",
    "    fig.suptitle(f'Iteration: {i}, loss: {loss.detach().numpy()}', fontsize=16)\n",
    "    ax1.imshow(image)\n",
    "    ax1.axis('off')\n",
    "    ax1.title.set_text('Image')\n",
    "    ax2.imshow(label)\n",
    "    ax2.axis('off')\n",
    "    ax2.title.set_text('Label')\n",
    "    ax3.imshow(output.cpu().detach().numpy().reshape((200, 200)))\n",
    "    ax3.axis('off')\n",
    "    ax3.title.set_text('Prediction')\n",
    "    kernel = torch.sigmoid(list(model.conv.parameters())[0]).sum(axis=0).squeeze(0).permute(1, 2, 0).cpu().detach().numpy()/3\n",
    "    ax4.imshow(kernel)\n",
    "    ax4.axis('off')\n",
    "    ax4.title.set_text('Kernel')\n",
    "    plt.show()\n",
    "    plt.pause(0.1)\n",
    "\n",
    "# Change matplotlib backend back to inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15,15))\n",
    "fig.suptitle(f'Iteration: {i}, loss: {loss.detach().numpy()}', fontsize=16)\n",
    "ax1.imshow(image)\n",
    "ax1.axis('off')\n",
    "ax1.title.set_text('Image')\n",
    "ax2.imshow(label)\n",
    "ax2.axis('off')\n",
    "ax2.title.set_text('Label')\n",
    "ax3.imshow(output.cpu().detach().numpy().reshape((200, 200)))\n",
    "ax3.axis('off')\n",
    "ax3.title.set_text('Prediction')\n",
    "kernel = torch.sigmoid(list(model.conv.parameters())[0]).sum(axis=0).squeeze(0).permute(1, 2, 0).cpu().detach().numpy()/3\n",
    "ax4.imshow(kernel)\n",
    "ax4.axis('off')\n",
    "ax4.title.set_text('Kernel')\n",
    "plt.plot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
