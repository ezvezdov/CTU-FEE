{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "### Main goals\n",
    "##### Effective workflow \n",
    "    - Learn what tools to use in machine learning and how to effectively use it\n",
    "    - Learn what to do and also what NOT to do\n",
    "    - Learn estabilished habbits and best practices (git, prototyping, integration, optimization, ...)  \n",
    "##### Formalize computer vision applications into tasks\n",
    "    - Formalize inputs and outputs for vision-related problems\n",
    "    - Understand what data and computational requirements you need to train a model\n",
    "##### Develop and train models\n",
    "    - Learn to code, debug, and train convolutional neural networks.\n",
    "    - Learn how to use software frameworks like PyTorch and TensorFlow\n",
    "##### Gain an understanding of where the field is and where it is headed\n",
    "    - Learn what is the ever-green foundation of the field\n",
    "    - Learn what are the current trends and what can be achieved in the state-of-the-art\n",
    "    - https://www.jobs.cz/rpd/1594416698/?searchId=529d625d-e728-45cc-8462-a6466df52120&rps=233"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment\n",
    "    - Linux (Recommendation)\n",
    "    - Python\n",
    "    - Recommended Editor: VSCode, jupyter-lab, jupyter-notebook\n",
    "    - We recommend creating virtual environment for UROB through conda or virtualenv (implemented in your editor)\n",
    "    - https://cs231n.github.io/setup-instructions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Recommendations\n",
    "    * Save jupyter notebooks regularly!\n",
    "    * First imagine/simulate in head the result, then code!\n",
    "    * First try to find solution yourself, then ask a friend!\n",
    "    * Work hard, play hard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Today\n",
    "    - Get the students to at least the minimal necessary Python programming level\n",
    "    - Finish the Questions and Final task\n",
    "    - Full tutorial you need more reminds: https://cs231n.github.io/python-numpy-tutorial/\n",
    "    - You can skip what you know and are able to reproduce if the solution is invisible(!)\n",
    "    \n",
    "### Endpoint\n",
    "    Store this jupyter notebook with the name: \n",
    "    \n",
    "    **username.ipynb**,\n",
    "                \n",
    "    to:\n",
    "    \n",
    "    **username@taylor.felk.cvut.cz:/local/temporary/UROB/intro/**,\n",
    "    \n",
    "    till the end of the class. Use command:\n",
    "    \n",
    "    **scp username.ipynb username@taylor.felk.cvut.cz:/local/temporary/UROB/intro/**\n",
    "    \n",
    "    \n",
    "    If I like it, I will assign one points if finished in time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "You are given two points (xy) representing the mean of the data distributions:\n",
    "\n",
    "$$p_1 = (2, 1)$$\n",
    "\n",
    "$$p_2 = (5, 4)$$\n",
    "\n",
    "Find the **Decision boundary** using random search of the parameters, that assign 0 class to the first point and 1 class to the second point. The boundary is parametrized by a line:\n",
    "\n",
    "$$ ax+by+c=0$$\n",
    "\n",
    "The task represents a minimalistic example of what we are going to do here. You have the data (points), design the parametrized model (Decision boundary), find the criterion of \"good\" parameters (Loss) and optimize the parameters of the model based on success (Output equals target) of the prediction, see the ilustration:\n",
    "\n",
    "<img src=\"model.png\" alt=\"scheme\" width=\"600\"/>\n",
    "\n",
    "##### Answer/Code following questions (will help you in performing the task):\n",
    "\n",
    "1) Is the Line decision sufficient function to solve the problem?\n",
    "    - Yes\n",
    "    - No\n",
    "    \n",
    "    Answer: \n",
    "    \n",
    "2) Visualize the iterations of the parameter search\n",
    "    - Plot of Points and the boundary in each iteration\n",
    "    - Use plt.savefig(f'imgs/{iteration:03d}.png') to store visuals of each configuration (f'{iteration}' is recommended string formating for Python 3.7+) to an image file\n",
    "    \n",
    "    Answer: in Code\n",
    "\n",
    "3) Define function, that represents classification of the point\n",
    "    - Takes argument of Line parameters and point and return point class\n",
    "    \n",
    "    Answer: in Code\n",
    "    \n",
    "4) When to stop iteration?\n",
    "    \n",
    "    Answer: in Code\n",
    " \n",
    "5) List an **suitable** another criterion/loss for choosing the decision boundary other than class prediction\n",
    "    \n",
    "    Answer: \n",
    "    \n",
    "6) State 3 things that would make the program faster\n",
    "    \n",
    "    Answer:\n",
    "    a)\n",
    "    b)\n",
    "    c)\n",
    "\n",
    "7) Optimize the speed using numpy arrays (hint: get rid of the for loop)\n",
    "\n",
    "    Answer: in Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-07T07:17:24.773167866Z",
     "start_time": "2023-09-07T07:17:24.543692536Z"
    }
   },
   "outputs": [],
   "source": [
    "# Imports and preparation of the folder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "os.makedirs('imgs/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "\n",
    "You have the same setup as in the Task 1, but with more data samples from the original data distribution. Choose the parameters of the decision boundry from the Task 1 and apply it / plot it together with the other data.\n",
    "\n",
    "##### Answer/Code the following:\n",
    "1) Choose the best (according to you) Line parameter and plot it together with the original data (marked as stars) and rest of the distributions as points. Distinguish the distributions with colors.\n",
    "    \n",
    "    Answer: in Code\n",
    "\n",
    "2) Is it suitable for the other data samples as well? If not, why? Do you need more complicated function?\n",
    "    \n",
    "    Answer: \n",
    "    \n",
    "3) Are you able to design criterion, that would express the distribution more properly, if you know how it looks like? Does it relate to the apriori or aposteriory probability?\n",
    "    \n",
    "    Answer: \n",
    "\n",
    "4) After tunning the parameters more, what would you do about the \"lonely\" points, that are classified incorectly no matter what you do?\n",
    "    \n",
    "    Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original points\n",
    "x1 = 2\n",
    "y1 = 1\n",
    "\n",
    "x2 = 5\n",
    "y2 = 4\n",
    "\n",
    "# Data from the distributions, the number denotes to which point it belongs\n",
    "hidden_data1 = np.random.randn(50, 2) + np.array((x1, y1))\n",
    "hidden_data2 = np.random.randn(51, 2) + np.array((x2, y2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
